# Data Engineering

This repository contains resources to learn Data Engineering concepts

**What Is Data Engineering?**
<br/>Data engineering is the process of designing and building systems that let people collect and analyze raw data from multiple sources and formats. These systems empower people to find practical applications of the data, which businesses can use to thrive.
<!--- Diagram-->

**Why Is Data Engineering Important?**
<br/>Businesses, regardless of their size, are often faced with the daunting task of sifting through vast amounts of diverse data to address crucial inquiries. Data engineering is crafted to facilitate this process, enabling data consumers such as analysts, data scientists, and executives to thoroughly, swiftly, and securely examine all available data.

Analyzing data poses challenges due to its management across various technologies and diverse storage structures. However, analysis tools typically assume uniformity in data management and storage, leading to complications for those seeking insights into business performance.

Take, for instance, the multitude of customer data collected by a brand:

- Billing and shipping information reside in one system.
- Order history is maintained by another system.
- Customer support, behavioral data, and third-party information are stored in separate systems.

While collectively providing a holistic view of the customer, these disparate datasets operate independently, making it exceedingly difficult to answer specific questions, such as identifying which types of orders incur the highest customer support costs.

Data engineering addresses this challenge by integrating these disparate datasets, enabling swift and efficient retrieval of insights.

**What Do Data Engineers Do?**
The demand for data engineering skills is on the rise, with data engineers being pivotal in designing systems that streamline data integration and facilitate navigation. Data engineers undertake a variety of tasks, including:

- Acquisition: Identifying diverse datasets across the organization.
- Cleansing: Identifying and rectifying errors within the data.
- Conversion: Standardizing data into a uniform format.
- Disambiguation: Resolving ambiguous interpretations of data.
- Deduplication: Eliminating redundant instances of data.

Following these processes, data is often stored in a centralized repository like a data lake or data lakehouse. Additionally, data engineers may selectively copy and transfer subsets of data into a data warehouse.


**References**
- https://www.dremio.com/blog/
- https://www.databricks.com/blog
- https://news.apache.org/
